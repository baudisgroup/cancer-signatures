{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pipe line using 3 datasets, vanilla denoising AE, iNNvestiage backtrace, then PCA and TSNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matfile = 'data/sob_cyto.pkl'\n",
    "labelfile = 'data/sob_cyto_label.pkl'\n",
    "with open(matfile, 'rb') as fmat open(labelfile, 'rb') as flab:\n",
    "    feat_mat = pickle.load(fmat)\n",
    "    feat_label = pickle.load(flab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_scaled = preprocessing.MinMaxScaler().fit_transform(np.abs(feat_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = keras.callbacks.EarlyStopping(monitor='loss', patience=20,mode='min')\n",
    "input_size = feat_mat.shape[1]\n",
    "hidden_size = 800\n",
    "output_size = input_size\n",
    "epochs = 2000\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla DAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "noise_factor = 0.05\n",
    "feat_noisy = featmat_scaled + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=feat_mat.shape) \n",
    "feat_noisy = np.clip(feat_noisy, 0., 1.)\n",
    "\n",
    "x = Input(shape=(input_size,))\n",
    "h = Dense(hidden_size, activation='relu')(x)\n",
    "r = Dense(output_size, activation='sigmoid')(h)\n",
    "\n",
    "ae = Model(inputs=x, outputs=r)\n",
    "ae.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
    "\n",
    "history = ae.fit(feat_noisy, feat_noisy, batch_size=batch_size,epochs=epochs, callbacks = [early_stopping_monitor],shuffle=True)\n",
    "\n",
    "encoder = Model(x,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace back weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_analyzer = innvestigate.create_analyzer(\"lrp.epsilon\", encoder, neuron_selection_mode=\"index\")\n",
    "i = 0\n",
    "analysis = np.zeros(input_size)\n",
    "for neuron_index in range(hidden_size):\n",
    "    analysis = np.add(analysis, gradient_analyzer.analyze(feat_scaled, neuron_index))\n",
    "    i +=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/bands.pkl'\n",
    "with open(filepath, 'rb') as fi:\n",
    "    bands = pickle.load(fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sum = np.sum(analysis, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_amps = feat_sum[:int(input_size/2),]\n",
    "feat_dels = feat_sum[int(input_size/2):,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/bands.pkl'\n",
    "with open(filepath, 'rb') as fi:\n",
    "    bands = pickle.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands['amp'] = feat_amps\n",
    "bands['del'] = feat_dels\n",
    "bands['index'] = bands.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_amps = bands.nlargest(20, 'amp')\n",
    "top_dels = bands.nlargest(20, 'del')\n",
    "bot_amps = bands.nsmallest(20, 'amp')\n",
    "bot_dels = bands.nsmallest(20, 'del')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_index = top_amps['index'] + bot_amps['index'] + top_dels['index'] + bot_dels['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sub = feat_scaled.take(sub_index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "pca_result = pca.fit_transform(feat_sub)\n",
    "\n",
    "print('PCA done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "print ('Variance explained per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(pca_result, columns = ['pca1','pca2','pca3','pca4'])\n",
    "pca_df['label'] = feat_label\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax = sns.scatterplot(\n",
    "    x=\"pca1\", y=\"pca2\",\n",
    "    hue=\"label\",\n",
    "    palette=sns.color_palette(\"hls\", 9),\n",
    "    data=pca_df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "tsne = TSNE(random_state=RS, perplexity=40).fit_transform(feat_sub)\n",
    "\n",
    "print ('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = pd.DataFrame(tsne, columns = ['tsne1','tsne2'])\n",
    "tsne_df['label'] = feat_label\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax = sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\",\n",
    "    hue=\"label\",\n",
    "    palette=sns.color_palette(\"hls\", 9),\n",
    "    data=tsne_df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    km = KMeans(n_clusters=i).fit(feat_sub)\n",
    "    clusters.append(km.inertia_)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.lineplot(x=list(range(1, 11)), y=clusters, ax=ax)\n",
    "ax.set_title('Searching for Elbow')\n",
    "ax.set_xlabel('Clusters')\n",
    "ax.set_ylabel('Inertia')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km3 = KMeans(n_clusters=3).fit(feat_sub)\n",
    "km3_df = pd.DataFrame({'km3_label': km3.labels_, 'sample_label':labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "ax = sns.catplot(y=\"sample_label\", hue=\"km3_label\", kind=\"count\",\n",
    "            palette=\"pastel\", edgecolor=\".6\",\n",
    "            data=km3_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
